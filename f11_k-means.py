import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import os

# ---------------------------------------------------------
# è¨­å®šï¼šè§£æ±ºåœ–è¡¨ä¸­æ–‡å­—å‹å¯èƒ½å‡ºç¾çš„äº‚ç¢¼å•é¡Œ (é¸ç”¨)
# Windows ç”¨æˆ¶é€šå¸¸è¨­ç‚º 'Microsoft JhengHei' (å¾®è»Ÿæ­£é»‘é«”)
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] 
plt.rcParams['axes.unicode_minus'] = False
# ---------------------------------------------------------

def main():
    # ---------------------------------------------------------
    # 1. è³‡æ–™è®€å–
    # ---------------------------------------------------------
    # å»ºè­°ä½¿ç”¨ç›¸å°è·¯å¾‘ï¼Œç¢ºä¿ä½ çš„çµ‚ç«¯æ©Ÿæ˜¯åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œ
    file_path = os.path.join('data', 'features', 'account_features_v1.csv')

    if not os.path.exists(file_path):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}")
        print("ğŸ’¡ è«‹ç¢ºèªä½ çš„çµ‚ç«¯æ©Ÿè·¯å¾‘æ˜¯å¦åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼Œä¸”æª”æ¡ˆè·¯å¾‘æ­£ç¢ºã€‚")
        return

    df = pd.read_csv(file_path)
    print(f"âœ… æˆåŠŸè®€å–è³‡æ–™ï¼Œå…± {df.shape[0]} ç­†å¸³æˆ¶ï¼Œ{df.shape[1]} å€‹æ¬„ä½ã€‚")

    # ---------------------------------------------------------
    # 2. ç‰¹å¾µé¸å– (Feature Selection)
    # ---------------------------------------------------------
    selected_features = [
        'mobile_bank_ratio', 'channel_entropy', 'txn_cnt', 
        'total_amt', 'std_amt', 'max_amt', 
        'active_days', 'night_cnt', 
        'min_txn_gap', 'std_txn_gap', 'max_txn_per_day'
    ]

    # æª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨ï¼Œé¿å…å ±éŒ¯
    missing_cols = [col for col in selected_features if col not in df.columns]
    if missing_cols:
        print(f"âŒ è³‡æ–™ç¼ºå°‘ä»¥ä¸‹æ¬„ä½ï¼Œç„¡æ³•åŸ·è¡Œï¼š{missing_cols}")
        return

    X = df[selected_features].copy()

    # ---------------------------------------------------------
    # 3. è³‡æ–™å‰è™•ç† (Preprocessing)
    # ---------------------------------------------------------
    print("\nğŸ”„ æ­£åœ¨é€²è¡Œè³‡æ–™å‰è™•ç†...")

    # å¡«è£œç©ºå€¼
    X = X.fillna(0)

    # Log Transform
    log_cols = [
        'total_amt', 'max_amt', 'std_amt',
        'min_txn_gap', 'std_txn_gap'
    ]

    # æª¢æŸ¥ log_cols æ˜¯å¦éƒ½åœ¨ X è£¡
    valid_log_cols = [c for c in log_cols if c in X.columns]

    for col in valid_log_cols:
        # ç¢ºä¿æ•¸å€¼éè² 
        mask = X[col] < 0
        if mask.any():
            print(f"âš ï¸ è­¦å‘Šï¼š{col} å«æœ‰è² å€¼ï¼Œå°‡è¢«è¦–ç‚º 0 è™•ç†ã€‚")
            X.loc[mask, col] = 0
        X[col] = np.log1p(X[col])

    # StandardScaler
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # ---------------------------------------------------------
    # 3.5 æ‰‹è‚˜æ³• (Elbow Method) - äº’å‹•å¼
    # ---------------------------------------------------------
    # print("\nğŸ“‰ æ­£åœ¨è¨ˆç®—æ‰‹è‚˜æ³• (é€™å¯èƒ½éœ€è¦ä¸€é»æ™‚é–“)...")

    # k_range = range(2, 16)
    # inertias = []

    # for k in k_range:
    #     kmeans_test = KMeans(n_clusters=k, random_state=42, n_init=10)
    #     kmeans_test.fit(X_scaled)
    #     inertias.append(kmeans_test.inertia_)

    # # ç¹ªåœ–
    # plt.figure(figsize=(10, 6))
    # plt.plot(k_range, inertias, marker='o', linestyle='-', color='b')
    # plt.title('Elbow Method (Inertia vs K)')
    # plt.xlabel('Number of Clusters (K)')
    # plt.ylabel('Inertia')
    # plt.grid(True, alpha=0.3)
    # plt.xticks(k_range)

    # print("\nğŸ‘€ æ‰‹è‚˜æ³•åœ–è¡¨å·²é–‹å•Ÿï¼Œè«‹æŸ¥çœ‹è¦–çª—ã€‚")
    # print("ğŸ’¡ é—œé–‰åœ–è¡¨è¦–çª—å¾Œï¼Œç¨‹å¼æœƒç¹¼çºŒåŸ·è¡Œ...")

    # plt.show() # ç¨‹å¼æœƒåœ¨é€™è£¡æš«åœï¼Œç›´åˆ°ä½ é—œé–‰åœ–è¡¨è¦–çª—

    # --------------------------------------------------------
    # 4. K-Means åˆ†ç¾¤ (äº’å‹•å¼æ±ºå®š K)
    # ---------------------------------------------------------
    while True:
        user_input = input("\nğŸ‘‰ è«‹è¼¸å…¥ä½ æƒ³ä½¿ç”¨çš„ K å€¼ (é è¨­ 6ï¼Œç›´æ¥æŒ‰ Enter ä½¿ç”¨é è¨­å€¼): ").strip()
        if user_input == "":
            K = 6
            break
        elif user_input.isdigit() and int(user_input) > 1:
            K = int(user_input)
            break
        else:
            print("âŒ è¼¸å…¥ç„¡æ•ˆï¼Œè«‹è¼¸å…¥å¤§æ–¼ 1 çš„æ•´æ•¸ã€‚")

    print(f"\nğŸš€ æ­£åœ¨åŸ·è¡Œ K-Means åˆ†ç¾¤ (K={K})...")

    kmeans = KMeans(n_clusters=K, random_state=42, n_init=20)
    cluster_labels = kmeans.fit_predict(X_scaled)
    df['cluster_group'] = cluster_labels

    print("\nğŸ“Š å„ç¾¤çµ„å¸³æˆ¶æ•¸é‡çµ±è¨ˆï¼š")
    print(df['cluster_group'].value_counts().sort_index())

    # ---------------------------------------------------------
    # 5. çµæœè¦–è¦ºåŒ– (PCA é™ç¶­) - åŠ å¼·ç‰ˆ
    # ---------------------------------------------------------
    print("\nğŸ¨ æ­£åœ¨ç¹ªè£½ PCA åˆ†ç¾¤åœ–...")

    # åŸ·è¡Œ PCA
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_scaled)

    # å–å¾—è§£é‡‹è®Šç•°é‡ (Explained Variance Ratio)
    # é€™å‘Šè¨´æˆ‘å€‘ PC1 å’Œ PC2 åˆ†åˆ¥è§£é‡‹äº†å¤šå°‘åŸæœ¬è³‡æ–™çš„è®Šç•°
    explained_variance = pca.explained_variance_ratio_
    pc1_var = explained_variance[0] * 100
    pc2_var = explained_variance[1] * 100

    # -----------------------------------------------------
    # ğŸ’¡ æ•™æˆåŠ ç¢¼ï¼šåˆ†æ PC1 å’Œ PC2 åˆ°åº•æ˜¯ç”±å“ªäº›ç‰¹å¾µçµ„æˆçš„ï¼Ÿ
    # -----------------------------------------------------
    components = pd.DataFrame(pca.components_, columns=selected_features, index=['PC1', 'PC2'])
    print("\nğŸ” PCA ä¸»æˆåˆ†åˆ†æè§£å¯† (æ‰¾å‡ºå½±éŸ¿ X/Y è»¸æœ€å¤§çš„ç‰¹å¾µ):")

    for i, pc in enumerate(['PC1', 'PC2']):
        print(f"\n--- {pc} (è§£é‡‹åŠ›: {explained_variance[i]*100:.1f}%) ä¸»è¦å—ä»¥ä¸‹ç‰¹å¾µå½±éŸ¿ ---")

        # æ‰¾å‡ºå½±éŸ¿åŠ›çµ•å°å€¼æœ€å¤§çš„å‰ 3 å€‹ç‰¹å¾µ
        top_features = components.iloc[i].abs().sort_values(ascending=False).head(3)
        for feature, weight in top_features.items():
            # é¡¯ç¤ºåŸå§‹æ¬Šé‡ (æ­£å€¼ä»£è¡¨æ­£ç›¸é—œï¼Œè² å€¼ä»£è¡¨è² ç›¸é—œ)
            raw_weight = components.loc[pc, feature]
            direction = "æ­£å‘" if raw_weight > 0 else "è² å‘"
            print(f"   * {feature}: {raw_weight:.4f} ({direction})")

    print("-" * 50)

    # -----------------------------------------------------
    # é–‹å§‹ç•«åœ–
    # -----------------------------------------------------
    # plt.figure(figsize=(10, 8))
    # sns.scatterplot(
    #     x=X_pca[:, 0],
    #     y=X_pca[:, 1],
    #     hue=cluster_labels,
    #     palette='viridis',
    #     alpha=0.6,
    #     s=20 # é»ç¨å¾®å¤§ä¸€é»æ¯”è¼ƒæ¸…æ¥š
    # )

    # # è¨­å®šæ¨™é¡Œèˆ‡è»¸åç¨± (åŠ å…¥è®Šç•°é‡èªªæ˜)
    # plt.title(f'K-Means Clustering (K={K}) - PCA Projection\nTotal Variance Explained: {pc1_var + pc2_var:.1f}%')
    # plt.xlabel(f'PC1 (Dim 1) - {pc1_var:.1f}% Variance')
    # plt.ylabel(f'PC2 (Dim 2) - {pc2_var:.1f}% Variance')
    # plt.legend(title='Cluster Group')
    # plt.grid(True, alpha=0.3)

    # print("ğŸ‘€ PCA åœ–è¡¨å·²é–‹å•Ÿï¼Œè«‹æŸ¥çœ‹è¦–çª—ã€‚")
    # print("ğŸ’¡ æç¤ºï¼šX è»¸æ•¸å€¼è¶Šå¤§ï¼Œä»£è¡¨è©²é»åœ¨ PC1 çš„ç‰¹å¾µè¡¨ç¾è¶Šå¼·ï¼ˆè«‹å°ç…§ä¸Šæ–¹çš„è§£å¯†è³‡è¨Šï¼‰ã€‚")

    # plt.show()

    # ---------------------------------------------------------
    # 6. è¼¸å‡ºçµæœ
    # ---------------------------------------------------------
    # ç¢ºä¿è¼¸å‡ºè·¯å¾‘å­˜åœ¨
    output_dir = os.path.dirname(file_path) # å­˜å›åŸæœ¬è®€å–æª”æ¡ˆçš„ç›®éŒ„
    output_file = os.path.join(output_dir, 'account_features_with_cluster.csv')

    df.to_csv(output_file, index=False)
    print(f"\nâœ… åˆ†ç¾¤çµæœå·²å„²å­˜ç‚º: {output_file}")
    print("ä½ å¯ä»¥é–‹å•Ÿæ­¤ CSV æª”é€²è¡Œå¾ŒçºŒåˆ†æã€‚")

if __name__ == "__main__":
    main()